{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ec3f01-48af-4a82-8d17-72a249b6c436",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f851839-557f-43d0-b4a4-12304897dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav, sr = torchaudio.load(\"../data/raw/eval_data/eval_data/slider/test/id_01_00000001.wav\")\n",
    "        # print(f\"{sr=}\")\n",
    "        # print(f\"{wav.shape=}\")\n",
    "        \n",
    "\n",
    "n_mels = 128\n",
    "frames = 5\n",
    "n_fft = 1024\n",
    "hop_length = 512\n",
    "power = 2.0\n",
    "\n",
    "melspec_transformer = T.MelSpectrogram(sample_rate=sr,\n",
    "                             n_fft=n_fft,\n",
    "                             hop_length=hop_length,\n",
    "                             n_mels=n_mels,\n",
    "                             power=power)\n",
    "mel = melspec_transformer(wav).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3845f9fb-6896-4223-8ff9-fc8f91e50858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import SliderDataset\n",
    "import torch\n",
    "\n",
    "n_mels = 128\n",
    "frames = 5\n",
    "n_fft = 1024\n",
    "hop_length = 512\n",
    "power = 2.0\n",
    "\n",
    "ds_spec = SliderDataset(\"../data/raw/dev_data/dev_data/slider/test/\",\n",
    "                n_mels=n_mels,\n",
    "                frames=frames,\n",
    "                n_fft=n_fft,\n",
    "                hop_length=hop_length,\n",
    "                power=power,\n",
    "                use_cnn=True,\n",
    "                normalize=False\n",
    ")\n",
    "xs = []\n",
    "for i, item in enumerate(ds_spec):\n",
    "    xs.append(item[\"input\"].squeeze())\n",
    "    if i > 10:\n",
    "        break\n",
    "    \n",
    "xs_spec = torch.cat(xs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bf02ae8-3623-408b-9dc3-5476a5f85961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3756, 128])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "adc7c4d3-7852-49a0-87e7-c535962edd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building index for spectrogram columns: 100%|██████████| 1101/1101 [00:02<00:00, 380.85it/s]\n"
     ]
    }
   ],
   "source": [
    "ds_cols = SliderDataset(\"../data/raw/dev_data/dev_data/slider/test/\",\n",
    "                n_mels=n_mels,\n",
    "                frames=frames,\n",
    "                n_fft=n_fft,\n",
    "                hop_length=hop_length,\n",
    "                power=power,\n",
    "                use_cnn=True,\n",
    "                normalize=False,\n",
    "                iter_over_cols=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64334c49-a988-455e-bab3-8008ad764080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3756/344613 [00:00<00:03, 102369.23it/s]\n"
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "from tqdm import tqdm\n",
    "for i, item in enumerate(tqdm(ds_cols)):\n",
    "    if i > 3755:\n",
    "        break\n",
    "    xs.append(item[\"input\"].squeeze())\n",
    "\n",
    "    \n",
    "xs_cols = torch.stack(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c0ce7e34-883c-42b7-b991-d4496f03b9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3756, 128])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33194ce3-d2d5-459d-935b-6d86fb6d62f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3756\n",
    "(xs_spec[:n] - xs_cols[:n]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef5b2a88-248c-4136-aaca-906ba9855c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 312, 128])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_spec[0]['input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "58ce39ca-75ca-410c-8825-5f3b71c7e434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
